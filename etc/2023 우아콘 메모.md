# 대규모 트랜잭션을 처리하는 배민 주문시스템 규모에 따른 진화

배민 주문 시스템의 특징
- 순간적으로 몰리는 트랜잭션 - 점심, 저녁 시간에 주문수가 집중됨
- MSA - 이벤트 기반으로 여러 시스템과 연계
- 대용량 데이터 (일평균 300만건 주문 발생)

문제점
- 단일 장애 포인트 - 하나의 시스템 장애가 여러 시스템의 장애로
    - 메시지 큐를 통해 이벤트 기반 통신 도입 -> 시스템 간 영향도 분리
- 대용량 데이터 - RDBMS 조인 연산으로 인해 떨어지는 조회 성능
    - 조회와 쓰기가 같은 DB에서 이뤄지고 있음
    - id로 조회할 수 있게끔?? 못들었는데 id로 조회해서 매핑한건가
    - 저장과 조회 분리 (CQRS 아키텍쳐 패턴 적용)
    - 조회 모델 역 정규화
- 대규모 트랜잭션 - 저장소의 쓰기 처리량 한계 + 더이상 장비 성능이 힘든 상황
    - 읽기 부하 분산 -> 스케일아웃
    - 쓰기 부하 분산 -> 스케일업 -> AWS의 최고 스펙으로도 한계에 다다름
    - DB 샤딩 -> AWS Aurora DB에서 미지원
    - 애플리케이션 딴에서 샤딩 진행
        1. key based
            - shard key 이용
            - 주문번호 (shard key)를 hash function에 넣은 결과값 이용
        2. range based
            - 값의 범위 이용 - 가격 기반으로 고민
            - 구현이 간단하지만 데이터 균등하게 배분 X
        3. directory based
            - look up table 이용
            - 매핑용 테이블을 따로 두는 용인듯
            - 동적으로 샤드 추가하는데 편함
            - look up table이 단일 장애 포인트 가능
    - 주문시스템 특징에 따라 샤딩 방식 정함
        - 주문 정상 동작하지 않으면 서비스에 크리티컬한 사용자 경험 -> 단일 장애 포인트는 피한다
        - 동적 주문 데이터는 최대 30일만 저장한다. -> 샤드 추가 이후 30일 지나면 데이터 다시 균등하게 분배될 것
        - 따라서 key based sharding 이용
    - AOP, AbstractRoutingDataSource 이용해 구현 - ThreadLocal 이용해서 어떤 DB에서 조회할지 잘 분배시켰다는듯
    - 그렇다면 쓰기 DB는 샤딩을 통해 구성했는데 조회는 어케??
        - 조회성 데이터는 몽고DB에 저장되어있어서 ㄱㅊ
- 복잡한 이벤트 아키텍처 - 무분별한 이벤트 발행으로 서비스 복잡도 상승 ====> #TODO  이 부분 나중에 영상으로 다시 들어보자 제대로 이해 못함
    1. 스프링 애플리케이션 이벤트는 로직을 수행하는 주체를 파악하기 어렵다
    2. 이벤트 유실이 발생하면 재처리가 어려움
    - 주문 도메인 이벤트(SQS에 메시지 보내는..?):  내부 이벤트 + 서비스 로직: 외부 이벤트로 정의(외부에서 서비스 받는건가)
    - 내부 이벤트: Zero Payload 전략 사용. 그때그때 필요한 데이터를 추가해주자..?
    - 트랜잭션 아웃박스 패턴: 이벤트 발행 실패와 서비스 실패를 격리하여 재발행 수단 보장. -> 이벤트 유실이 발생해도 아웃박스 엔티티를 통해 재발행이 가능하게 만들 수 있었다

# 배민스토어에 최신 기술 한방에 때려넣기
EDA; Event Driven Architecture
- Zero payload 이야기가 많네
- 여기저기 흩어진 데이터를 주워모으느라 조회 시간이 너무 길다 -> 전시에 최적화된 DB를 만들어 조회시간 최소화
- DLT를 적극적으로 활용 -> 스스로 복원력을 갖는 시스템. 실패 저장소 혹은 이벤트 재발행
- 동기식으로 연동하는 API는 서킷브레이커

WebFlux
- 러닝커브가 높다. 개발할때 이걸 어떻게 만들지보다는 WebFlux의 어떤 메서드를 호출해야하지? 같은 관점으로 바뀌게 됨
- 실시간으로 호출하는 외부 API가 너무 많아서 고려하게 됨
- pinpoint 사용중이라면 명확하게 안나타날수도 있음
- 그럼… WebFlux의 단점들을 다 견디고 그냥 성능 때문에 사용하는건가..??

어떻게 신기술 도입을 할까
- 꾸준한 팀 스터디
- 원활한 팁 공유 - 슬랙으로 그냥 수시로 공유하는듯

# 낯선 서드 파티와의 동행
- 비동기 검증으로 영향도 최소화
- 반복적인 운영 업무 -> 일괄로 처리 가능하도록 -> 이걸 배치까지 추가해서
- long transaction으로 인한 서버 다운
    - 서드파티 연동을 트랜잭션에서 분리
    - 서킷브레이커 도입

걍.. 잡생각..
- 발표 자료에 코드 넣을때 클래스명이나 메서드명을 한글로 쓰니까 눈에 잘보이네

# 카프카를 활용한 이벤트 기반 아키텍쳐 구축
이벤트 기반 아키텍쳐를 왜 적용했는가
- 배달 기능은 강한 일관성 X (관련 기능들이 반드시 동시에 반영될 필요 X. 처리가 되기만 하면 됨) => 결과적 일관성
- 결과적 일반성을 이벤트로 표현 가능

이벤트의 구성요소
- 대상: 이벤트가 일어나는 고유..? 머..? 데이터?
- 행동: 이미 벌어진 사건. 과거형
- 정보: 행위와 관련된 값
- 시간: 행위가 발생한 시간

주의사항
- 소비처 요구사항에 대한 무분별한 데이터 추가 주의 (행위자 기반의 데이터 정의 필요)
- 이벤트의 순서가 매우 중요
    - 주문 취소 후 주문 생성 이벤트가 들어와버리면? X
    - 이벤트 파이프라인 도입

메시지 브로커로 카프카 선택
- 순서 보장: 토픽의 파티션을 통해 key별로 순서 보장 
- 고가용성
- 통합 도구: 카프카에서 제공해주는 다양한 통합 도구 제공
- 등등

카프카 도입 후 문제
- 이벤트 발행이 실패하거나 재시도하며 이벤트 순서 변경이 일어남
    - 도메인 상태와 발행 결과가 달라 장애 발생
    - Transactional outbox pattern 도입
        - debezium 활용
            - 안정성: binary log를 통한 순서 보장 및 offeset 활용한 발행 보장
            - 처리량: outbox 테이블 파티셔닝을 통한 처리량 증대 
            - 등등

이벤트의 활용 사례
- 순서가 보장된 이벤트..
- 이벤트 스트림 기반으로 CQRS 적용
- 이벤트 스트림으로 스트림즈 애플리케이션 구현
    - 실시간 데이터 제공, 모니터링 등 다양한 기능에 활용 가능
